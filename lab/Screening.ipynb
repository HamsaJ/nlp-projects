{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ranking candidate CVs using keywords and semantic matching\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load CVs\n",
    "with open('test_CVs.json') as in_file:\n",
    "    test_data = json.load(in_file)\n",
    "    \n",
    "# Load CVs\n",
    "with open('test_job_listing.json') as in_file:\n",
    "    job_data = json.load(in_file)\n",
    "\n",
    "titles = [item[0] for item in test_data['data']]\n",
    "CVs = [item[1] for item in test_data['data']]\n",
    "\n",
    "company = job_data['data'].split(\"#\")[0]\n",
    "job_listing = job_data['data'].split(\"#\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company: Brave \n",
      " Job listing: Brave is looking for an experienced Machine Learning engineer to help build our Brave Web Browser. It's already receiving rave reviews and we are only just beginning. Jump in and work with a top-notch\n"
     ]
    }
   ],
   "source": [
    "print(\"Company:\", company,\"\\n\", \"Job listing:\", job_listing[0:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  \t  Assistant Retail Manager  : \t Assistant Retail Manager    ROBERT SMITH    Phone: (123) 456 78 99 Email: info@qwikresume.com Websit\n",
      "1  \t  Python Developer/Tester  : \t     ROBERT SMITH    Python Developer/Tester    info@qwikresume.com | LinkedIn Profile | Qwikresume.c\n",
      "2  \t  SOFTWARE EXPERT  : \t Anthony Applicant    567 North Street  •  Boston, MA 02108  •  (123) 456-7890  •  anthony.applicant@\n",
      "3  \t  Full Stack Python Developer  : \t E­mail: info@qwikresumc.com    ROBERT SMITH Full Stack Python Developer    SUMMARY    Phone: (0123)­\n",
      "4  \t  Python Developer  : \t CONTACT DETAILS    1737 Marshville Road, Alabama    (123)-456-7899 info@qwikresume.com www.qwikresum\n",
      "5  \t  Data Scientist  : \t Malik Rabb      Seattle, WA • (123) 456-7891      mrabb@email.com            SUMMARY      Data Scien\n"
     ]
    }
   ],
   "source": [
    "# Display \n",
    "for idx in range(len(CVs)):\n",
    "    print(idx, \" \\t \", titles[idx], \" : \\t\", CVs[idx][:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sec1\"></a>\n",
    "## 1. TF-IDF to score shared key words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/jama/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('punkt')\n",
    "stop_words = set(stopwords.words('english')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.134 \t Data Scientist\n",
      "0.063 \t SOFTWARE EXPERT\n",
      "0.059 \t Python Developer\n",
      "0.047 \t Full Stack Python Developer\n",
      "0.031 \t Python Developer/Tester\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words=stop_words)\n",
    "vectors = vectorizer.fit_transform([job_listing] + CVs)\n",
    "\n",
    "# Calculate the word frequency, and calculate the cosine similarity of the search terms to the CVs\n",
    "cosine_similarities = linear_kernel(vectors[0:1], vectors).flatten()\n",
    "applicant_scores = [item.item() for item in cosine_similarities[1:]]  # convert back to native Python dtypes\n",
    "\n",
    "# Print the top-scoring results and their titles\n",
    "score_titles = [(score, title) for score, title in zip(applicant_scores, titles)]\n",
    "\n",
    "for score, title in (sorted(score_titles, reverse=True, key=lambda x: x[0])[:5]):\n",
    "    print(f'{score:0.3f} \\t {title}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sec1b\"></a>\n",
    "## 1b. Using a lemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lemmatizer reduces words down to their simplest 'lemma'. This is particularly helpful with dealing with plurals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from: https://scikit-learn.org/stable/modules/feature_extraction.html\n",
    "\n",
    "from nltk import word_tokenize          \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "class LemmaTokenizer:\n",
    "    \"\"\"\n",
    "    Interface to the WordNet lemmatizer from nltk\n",
    "    \"\"\"\n",
    "    ignore_tokens = [',', '.', ';', ':', '\"', '``', \"''\", '`']\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, doc):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(doc) if t not in self.ignore_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/jama/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['It', 'wa', 'raining', 'cat', 'and', 'dog', 'in', 'FooBar']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Demonstrate the job of the tokenizer\n",
    "nltk.download('wordnet')\n",
    "tokenizer=LemmaTokenizer()\n",
    "\n",
    "tokenizer('It was raining cats and dogs in FooBar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.143 \t Data Scientist\n",
      "0.060 \t SOFTWARE EXPERT\n",
      "0.040 \t Python Developer\n",
      "0.038 \t Full Stack Python Developer\n",
      "0.036 \t Python Developer/Tester\n"
     ]
    }
   ],
   "source": [
    "# Initialise TfidfVectorizer with the LemmaTokenizer. Also need to lemmatize the stop words as well\n",
    "token_stop = tokenizer(' '.join(stop_words))\n",
    "vectorizer = TfidfVectorizer(stop_words=token_stop, tokenizer=tokenizer)\n",
    "\n",
    "# Calculate the word frequency, and calculate the cosine similarity of the search terms to the CVs\n",
    "vectors = vectorizer.fit_transform([job_listing] + CVs)\n",
    "cosine_similarities = linear_kernel(vectors[0:1], vectors).flatten()\n",
    "\n",
    "document_scores = [item.item() for item in cosine_similarities[1:]]  # convert back to native Python dtypes\n",
    "\n",
    "score_titles = [(score, title) for score, title in zip(document_scores, titles)]\n",
    "\n",
    "for score, title in (sorted(score_titles, reverse=True, key=lambda x: x[0])[:5]):\n",
    "    print(f'{score:0.3f} \\t {title}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sec1c\"></a>\n",
    "## 1c. Using the standalone module\n",
    "\n",
    "You can find the above functionality (TFidfVectorizer, stop_words, LemmaTokenizer, cosine_similarity) inside the `tfidf.py` module. This allows document scores to be calculated from a single function call: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/jama/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from tfidf import rank_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_scores = rank_documents(job_listing, CVs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.143 \t Data Scientist\n",
      "0.060 \t SOFTWARE EXPERT\n",
      "0.040 \t Python Developer\n",
      "0.038 \t Full Stack Python Developer\n",
      "0.036 \t Python Developer/Tester\n"
     ]
    }
   ],
   "source": [
    "score_titles = [(score, title) for score, title in zip(cv_scores, titles)]\n",
    "\n",
    "for score, title in (sorted(score_titles, reverse=True, key=lambda x: x[0])[:5]):\n",
    "    print(f'{score:0.3f} \\t {title}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sec2\"></a>\n",
    "## 2. Semantic matching using GloVe embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "from re import sub\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import gensim.downloader as api\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import TfidfModel\n",
    "from gensim.models import WordEmbeddingSimilarityIndex\n",
    "from gensim.similarities import SparseTermSimilarityMatrix\n",
    "from gensim.similarities import SoftCosineSimilarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# Initialize logging.\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.WARNING)  # DEBUG # INFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/jama/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# Import and download stopwords from NLTK.\n",
    "nltk.download('stopwords')  # Download stopwords list.\n",
    "stopwords = set(nltk.corpus.stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support functions for pre-processing and calculation\n",
    "# From: https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/soft_cosine_tutorial.ipynb\n",
    "\n",
    "def preprocess(doc):\n",
    "    # Tokenize, clean up input document string\n",
    "    doc = sub(r'<img[^<>]+(>|$)', \" image_token \", doc)\n",
    "    doc = sub(r'<[^<>]+(>|$)', \" \", doc)\n",
    "    doc = sub(r'\\[img_assist[^]]*?\\]', \" \", doc)\n",
    "    doc = sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', \" url_token \", doc)\n",
    "    return [token for token in simple_preprocess(doc, min_len=0, max_len=float(\"inf\")) if token not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the CVs, including the job application\n",
    "corpus = [preprocess(document) for document in CVs]\n",
    "job_list = preprocess(job_listing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the model\n",
    "\n",
    "The word embedding model is a large file, so loading is quite a long-running task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.4 s, sys: 154 ms, total: 20.5 s\n",
      "Wall time: 21.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Download and/or load the GloVe word vector embeddings\n",
    "\n",
    "if 'glove' not in locals():  # only load if not already in memory\n",
    "    glove = api.load(\"glove-wiki-gigaword-50\")\n",
    "    \n",
    "similarity_index = WordEmbeddingSimilarityIndex(glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.7 s, sys: 228 ms, total: 19.9 s\n",
      "Wall time: 5.12 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Build the term dictionary, TF-idf model\n",
    "# The search query must be in the dictionary as well, in case the terms do not overlap with the CVs (we still want similarity)\n",
    "dictionary = Dictionary(corpus+[job_list])\n",
    "tfidf = TfidfModel(dictionary=dictionary)\n",
    "\n",
    "# Create the term similarity matrix. \n",
    "# The nonzero_limit enforces sparsity by limiting the number of non-zero terms in each column. \n",
    "# For my application, I got best results by removing the default value of 100\n",
    "similarity_matrix = SparseTermSimilarityMatrix(similarity_index, dictionary, tfidf)  # , nonzero_limit=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Soft Cosine Measure between the job listing and the CVs.\n",
    "query_tf = tfidf[dictionary.doc2bow(job_list)]\n",
    "\n",
    "index = SoftCosineSimilarity(\n",
    "            tfidf[[dictionary.doc2bow(document) for document in corpus]],\n",
    "            similarity_matrix)\n",
    "\n",
    "doc_similarity_scores = index[query_tf]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output the document similarity results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 \t 0.653 \t Data Scientist\n",
      "4 \t 0.525 \t Python Developer\n",
      "3 \t 0.516 \t Full Stack Python Developer\n",
      "1 \t 0.446 \t Python Developer/Tester\n",
      "0 \t 0.414 \t Assistant Retail Manager\n",
      "2 \t 0.360 \t SOFTWARE EXPERT\n"
     ]
    }
   ],
   "source": [
    "# Output the similarity scores for top 15 CVs\n",
    "sorted_indexes = np.argsort(doc_similarity_scores)[::-1]\n",
    "for idx in sorted_indexes[:15]:\n",
    "    print(f'{idx} \\t {doc_similarity_scores[idx]:0.3f} \\t {titles[idx]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the most relevant terms in the CVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each term in the job listing, what were the most similar words in each CV?\n",
    "doc_similar_terms = []\n",
    "max_results_per_doc = 5\n",
    "for term in job_list:\n",
    "    idx1 = dictionary.token2id[term]\n",
    "    for document in corpus:\n",
    "        results_this_doc = []\n",
    "        for word in set(document):\n",
    "            idx2 = dictionary.token2id[word]\n",
    "            score = similarity_matrix.matrix[idx1, idx2]\n",
    "            if score > 0.0:\n",
    "                results_this_doc.append((word, score))\n",
    "        results_this_doc = sorted(results_this_doc, reverse=True, key=lambda x: x[1])  # sort results by score\n",
    "        results_this_doc = results_this_doc[:min(len(results_this_doc), max_results_per_doc)]  # take the top results\n",
    "        doc_similar_terms.append(results_this_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 \t 0.653 \t Data Scientist  :  passionate\n",
      "4 \t 0.525 \t Python Developer  :  \n",
      "3 \t 0.516 \t Full Stack Python Developer  :  \n",
      "1 \t 0.446 \t Python Developer/Tester  :  \n",
      "0 \t 0.414 \t Assistant Retail Manager  :  \n",
      "2 \t 0.360 \t SOFTWARE EXPERT  :  hero\n"
     ]
    }
   ],
   "source": [
    "# Output the results for the top 15 CVs\n",
    "for idx in sorted_indexes[:15]:\n",
    "    similar_terms_string = ', '.join([result[0] for result in doc_similar_terms[idx]])\n",
    "    print(f'{idx} \\t {doc_similarity_scores[idx]:0.3f} \\t {titles[idx]}  :  {similar_terms_string}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows which terms in each of the documents were most similar to terms in the search query. What it doesn't show, however, is the exact contribution of each of the terms to the document score, as each word similarity score will be weighted by the term frequency. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sec2b\"></a>\n",
    "## 2b. Using the ready-made DocSim class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `DocSim` class wraps up functionality to prepare and compare data in a single object. It also persists the word embedding model to avoid having to reload it each time it is used. The word embedding model is loaded on initialisation, as this is quite a long-running task.\n",
    "\n",
    "`DocSim_threaded` has similar functionality, but loads the model in a separate thread. Similarity queries cannot be evaluated until the model is ready - check the status of the `model_ready` flag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import docsim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading default GloVe word vector model: glove-wiki-gigaword-50\n",
      "Model loaded\n",
      "CPU times: user 21.2 s, sys: 175 ms, total: 21.3 s\n",
      "Wall time: 22 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "docsim_obj = docsim.DocSim(verbose=True)\n",
    "# docsim_obj = docsim.DocSim_threaded(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ready: True\n"
     ]
    }
   ],
   "source": [
    "print(f'Model ready: {docsim_obj.model_ready}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 documents loaded into corpus\n",
      "CPU times: user 21.1 s, sys: 369 ms, total: 21.5 s\n",
      "Wall time: 5.55 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "similarities = docsim_obj.similarity_query(job_listing, CVs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 \t 0.653 \t Data Scientist\n",
      "4 \t 0.525 \t Python Developer\n",
      "3 \t 0.516 \t Full Stack Python Developer\n",
      "1 \t 0.446 \t Python Developer/Tester\n",
      "0 \t 0.414 \t Assistant Retail Manager\n",
      "2 \t 0.360 \t SOFTWARE EXPERT\n"
     ]
    }
   ],
   "source": [
    "# Output the similarity scores for top 15 CVs\n",
    "for idx, score in (sorted(enumerate(similarities), reverse=True, key=lambda x: x[1])[:15]):\n",
    "    print(f'{idx} \\t {score:0.3f} \\t {titles[idx]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary Results\n",
    "\n",
    "\n",
    "## Summary: TF-idf\n",
    "\n",
    "1. It’s fast and works well when documents are large and/or have lots of overlap.\n",
    "2. It looks for exact matches, so at the very least you should use a lemmatizer to take care of the plurals.\n",
    "3. When comparing short documents with limited-term variety — such as search queries — there is a risk that you will miss semantic relationships where there isn’t an exact word match.\n",
    "\n",
    "## Summary: Semantic similarity using GloVe\n",
    "\n",
    "1. It is more flexible as it doesn’t rely on finding exact matches.\n",
    "2. There is a lot more computation involved so it can be slower, and the word embedding models can be quite large and take a while to prepare for first use. This scales well, but running a single query is slow.\n",
    "3. Most words have some degree of similarity to other words, so almost all documents will have some non-zero similarity to other documents. Semantic similarity is good for ranking content in order, rather than making specific judgements about whether a document is or is not about a specific topic.\n",
    "\n",
    "## Preliminary results suggests semantic similarity using GloVe is the more suitable method for ranking CVs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
